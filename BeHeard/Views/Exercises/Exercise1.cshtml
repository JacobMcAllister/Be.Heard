@using Microsoft.AspNetCore.Http

<!--Exercises-->
@model BeHeard.Models.ExerciseViewModel

@{

}

<h1>Exercise 1</h1>

<p>These are the directions to the exercise</p>
<p>Speak your chosen syllable loudly for ~15 seconds</p>
<p>The meter will fill up according to your volume level</p>
<p>Don't let the volume drop!</p>

<!-- The canvas that will be used to render the input level -->
<canvas id="meter" width="500" height="50" style="border: 1px solid black;"></canvas>
<div id="Buttons">
    <button id="pauseButton" type="button">Pause</button>
    <!--<button type="button" onclick="pauseMic()">Pause</button>-->
</div>


<!--Tips for exercise-->
<div class="container p-5 my-5 bg-dark text-white">
    <div class="row">
        <h2>Nice Job!</h2>
        <h3>Keep it up!</h3>
        <h6>Here are some tips for next time!</h6>
        <div class="list-group list-group-flush">
            <a href="#" class="list-group-item">Be Sure to Practice Everyday.</a>
            <a href="#" class="list-group-item">If you get frustrated, take a break!</a>
            <a href="#" class="list-group-item">Small steps are ok, nobody got where they were going on the first try!</a>
        </div>
    </div>
</div>

<script>

    var canvasContext = null;
    var WIDTH = 500;
    var HEIGHT = 50;
    var drawID = null;
    var arraySize = null;
    var micAnalyser = null;

    // Grab our canvas
    canvasContext = document.getElementById("meter").getContext("2d");

    // fork getUserMedia for multiple browser versions, for those
    // that need prefixes
    navigator.getUserMedia = (navigator.getUserMedia ||
        navigator.webkitGetUserMedia ||
        navigator.mozGetUserMedia ||
        navigator.msGetUserMedia);

    // Get user mic
    // const inputMicStream = navigator.mediaDevices.getUserMedia({ audio: true, video: false });

    // Audio  context for processing sound
    var audioContext = new AudioContext();

    if (navigator.mediaDevices) {
        console.log('getUserMedia supported.');
        navigator.getUserMedia (
            // constraints - only audio needed for this app
            {
                audio: true
            },
            // Success callback
            function (stream) {
                // Create mic stream node
                const micStreamSourceNode = audioContext.createMediaStreamSource(stream);
                // Create audio analyser
                micAnalyser = audioContext.createAnalyser();
                // Connect
                micStreamSourceNode.connect(micAnalyser);

                animateVoice();

            },
            // Error callback
            function (err) {
                console.log('The following gUM error occured: ' + err);
            }
        );
    } else {
        console.log('getUserMedia not supported on your browser!');
    }

    function animateVoice() {

        // Create array of mic input data
        const dataArray = new Float32Array(micAnalyser.fftSize);

        // Clear canvas
        canvasContext.clearRect(0, 0, WIDTH, HEIGHT);

        function drawVolume() {
            var fillVol;
            // Clear canvas
            canvasContext.clearRect(0, 0, WIDTH, HEIGHT);

            // Fill array
            micAnalyser.getFloatTimeDomainData(dataArray);

            let sumSquares = 0.0;
            for (const amplitude of dataArray) { sumSquares += amplitude * amplitude; }
            volumeVal = Math.sqrt(sumSquares / dataArray.length);
            fillVol = volumeVal * WIDTH * 3.8;
            console.log(volumeVal);
            console.log(fillVol);
            if (fillVol > 175) {
                canvasContext.fillStyle = "#00ff00";
            }
            else {
                canvasContext.fillStyle = "#ff0000";
            }
            canvasContext.fillRect(0, 0, fillVol, HEIGHT);

            drawID = requestAnimationFrame(drawVolume);

        }

        drawVolume();
    }
    
    document.getElementById("pauseButton").onclick = function () { pause_Play() };

    function pause_Play() {
        if (audioContext.state === 'running') {
            audioContext.suspend().then(function () {
                document.getElementById("pauseButton").innerHTML = 'Play';
            });
        } else if (audioContext.state === 'suspended') {
            audioContext.resume().then(function () {
                document.getElementById("pauseButton").innerHTML = 'Pause';
            });
        }
    }

</script>